# agent/fetch_alerts.py

import feedparser
import os
import json
from datetime import datetime

# --- CONFIGURATION ---
FEED_FILE = "config/feeds.txt"
OUTPUT_DIR = "outputs"

# Output Files
BRIEF_FILE = os.path.join(OUTPUT_DIR, "EXECUTIVE_BRIEF.md")
CONTENT_FILE = os.path.join(OUTPUT_DIR, "CONTENT_STUDIO.md")
DASHBOARD_DATA = os.path.join(OUTPUT_DIR, "dashboard_data.json") # <--- NEW: Data for your Website

# --- ENTERPRISE INTELLIGENCE LOGIC ---

# 1. Topic Classifiers (Filters Signal from Noise)
CATEGORIES = {
    "GEOPOLITICS": ["war", "military", "border", "diplomat", "treaty", "sanction", "sovereignty", "empire", "strategic", "nuclear"],
    "CYBER & TECH": ["cyber", "hack", "ransomware", "data breach", "ai", "surveillance", "semiconductor", "digital", "crypto"],
    "GLOBAL ECONOMY": ["trade", "tariff", "supply chain", "inflation", "currency", "market", "imf", "oil", "energy", "debt"],
    "LEADERSHIP": ["election", "parliament", "ceo", "resignation", "scandal", "protest", "policy", "regime"]
}

# 2. LinkedIn "Hook" Templates (For Marketing)
HOOKS = [
    "This changes everything for global trade...",
    "Why smart executives are watching this region closely...",
    "The hidden risk no one is talking about...",
    "A lesson in modern power dynamics from today's headlines..."
]

def categorize_item(text):
    """Assigns a category based on keywords."""
    text = text.lower()
    for category, keywords in CATEGORIES.items():
        if any(word in text for word in keywords):
            return category
    return "GENERAL UPDATES"

def fetch_and_process():
    print("Avellon Intelligence: Scanning Global Feeds...")
    
    # 1. Check if feed file exists
    if not os.path.exists(FEED_FILE):
        print(f"Warning: {FEED_FILE} not found. Using default feeds.")
        feeds = ["http://feeds.bbci.co.uk/news/world/rss.xml"] 
    else:
        with open(FEED_FILE, "r") as f:
            feeds = [line.strip() for line in f.readlines() if line.strip()]

    # Initialize data structure
    processed_data = {cat: [] for cat in CATEGORIES.keys()}
    processed_data["GENERAL UPDATES"] = []

    seen_titles = set()
    total_scanned = 0

    # 2. Parse feeds
    for url in feeds:
        try:
            print(f"Fetching: {url}")
            feed = feedparser.parse(url)
            
            # Get top 8 entries per feed
            for entry in feed.entries[:8]:
                if entry.title in seen_titles: continue
                seen_titles.add(entry.title)
                total_scanned += 1

                # Analyze & Categorize
                full_text = f"{entry.title} {entry.get('summary', '')}"
                category = categorize_item(full_text)
                
                # Structure Data
                item = {
                    "title": entry.title,
                    "link": entry.link,
                    "summary": entry.summary[:200] + "..." if "summary" in entry else "No detail available.",
                    "source": feed.feed.get("title", "Global Wire"),
                    "published": entry.get("published", datetime.utcnow().strftime("%Y-%m-%d")) # Added for Dashboard
                }
                processed_data[category].append(item)
                
        except Exception as e:
            print(f"Failed to parse {url}: {e}")

    print(f"Scan complete. {total_scanned} items processed.")
    return processed_data

def generate_reports(data):
    today = datetime.utcnow().strftime("%d %B %Y")

    # --- 1. GENERATE DASHBOARD DATA (NEW FEATURE) ---
    # This creates the hidden JSON file that powers your internal website
    dashboard_json = {
        "generated_at": today,
        "stats": {k: len(v) for k, v in data.items()},
        "items": data
    }
    
    with open(DASHBOARD_DATA, "w", encoding="utf-8") as f:
        json.dump(dashboard_json, f, indent=4)
    
    # --- 2. THE EXECUTIVE BRIEF (UNCHANGED) ---
    brief_content = f"""# AVELLON INTELLIGENCE: DAILY EXECUTIVE BRIEF
**Date:** {today}
**Classification:** INTERNAL USE ONLY
**Focus:** Global Risk & Strategic Opportunity

---
"""
    has_news = False
    for category, items in data.items():
        if not items: continue
        has_news = True
        brief_content += f"\n## üèõ {category}\n"
        for item in items[:5]: # Top 5 per category
            brief_content += f"**‚ñ∫ {item['title']}**\n"
            brief_content += f"> *{item['summary']}* ([Source]({item['link']}))\n\n"

    if not has_news:
        brief_content += "\nNo significant risk updates found in today's scan.\n"

    brief_content += "---\n*Generated by Avellon Risk Engine v2.0*"

    # --- 3. THE CONTENT STUDIO (UNCHANGED) ---
    content_output = f"""# AVELLON MARKETING STUDIO
**Date:** {today}
**Goal:** Thought Leadership & Lead Gen
**Strategy:** Translate risk into business value.

---
"""
    for category, items in data.items():
        if not items or category == "GENERAL UPDATES": continue
        
        # Take the top story from a major category and frame it as a post
        top_story = items[0]
        
        content_output += f"## üìù DRAFT POST: {category.title()} Angle\n"
        content_output += f"**Source News:** {top_story['title']}\n\n"
        content_output += "**LinkedIn Hook Options:**\n"
        content_output += f"1. üõë {HOOKS[0]}\n"
        content_output += f"2. üí° {HOOKS[1]}\n\n"
        content_output += "**Draft Body Structure:**\n"
        content_output += f"- **The News:** {top_story['title']}\n"
        content_output += "- **The Insight:** This isn't just political; it's a warning signal for market stability.\n"
        content_output += "- **The Avellon View:** Resilience is the new currency. How is your organization preparing?\n\n"
        content_output += f"**Tags:** #AvellonIntelligence #RiskManagement #{category.replace(' & ', '')} #Strategy\n"
        content_output += "---\n\n"

    # Save Files
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    with open(BRIEF_FILE, "w", encoding="utf-8") as f:
        f.write(brief_content)
    
    with open(CONTENT_FILE, "w", encoding="utf-8") as f:
        f.write(content_output)

    print(f"Success! Reports generated:\n1. {DASHBOARD_DATA} (Dashboard)\n2. {BRIEF_FILE} (Internal)\n3. {CONTENT_FILE} (Marketing)")

def run_agent():
    data = fetch_and_process()
    generate_reports(data)

if __name__ == "__main__":
    run_agent()
